import base64
import requests
import os
import glob
import pyvips
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import requests
from config import API_KEY, GPT_MODEL, GPT_VISION_MODEL

# Convert SVG to PNG
def convert_svg_to_png(svg_file, png_file):
    image = pyvips.Image.new_from_file(svg_file, dpi=100)
    image.write_to_file(png_file)

# Function to encode the image
def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')
  
# Function to request user for text input
def get_user_input():
    user_input = input("Please describe the object you would like generated: ")
    return user_input

# Function to request user for the number of iterations
def get_number_of_iterations():
    iterations = input("Please enter the number of iterations: ")
    return iterations

# Function to extract svg code
def extract_svg_code(full_string):
    start_tag = '<svg'
    end_tag = '</svg>'

    # Find the start and end indices of the SVG code
    start_index = full_string.find(start_tag)
    end_index = full_string.find(end_tag)

    # Extract and return the SVG code
    # Add len(end_tag) to include the end tag in the output
    return full_string[start_index:end_index + len(end_tag)]

# Function to delete all files in a folder
def delete_files_in_folder(folder_path):
    files = glob.glob(folder_path + '/*')
    for f in files:
        os.remove(f)

# Function to generate SVG code using GPT
def generate_svg_code(user_input, first_iteration, conversation_history, feedback, api_key):

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Add user message to conversation history
    if (first_iteration):
        conversation_history.append(
        {
            "role": "system",
            "content": "You will generate vector graphics via SVG code. We will apply a reinforcement learning approach, where feedback will be provided in every iteration, and you will improve upon the vector graphic accordingly."
        })
        conversation_history.append(
        {
            "role": "user",
            "content": f"Generate simplistic SVG code representing a {user_input}. Ensure the SVG is of size 128x128."
        }    
        )
    else:
        conversation_history.append({
            "role": "user",
            "content": f"Generate simplistic SVG code representing a {user_input}. Ensure the SVG is of size 128x128. The feedback provided for the graphic generated in the prior iteration was: {feedback}"
        })

    payload = {
        "model": GPT_MODEL, 
        "messages": conversation_history,
        "max_tokens": 3000
    }

    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    response_json = response.json()
    content = response_json['choices'][0]['message']['content']
    
    # Append the response to the conversation history
    conversation_history.append({
        "role": "assistant",
        "content": content
    })
    tokens_used = response_json['usage']['total_tokens']
    return content, tokens_used
   
# Function to get image description from OpenAI
def get_image_feedback(base64_image, user_input, api_key):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "model": GPT_VISION_MODEL,
        "messages": [
            {
                "role": "system",
                "content": "You will be provided with images that were converted from SVG vector graphics. Evaluate and provide feedback on one thing that needs to change to improve the graphic.",
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "The attached image is the current output for a " + user_input + " generated by GPT using SVG code. Please provide concise feedback focusing on a single key aspect that needs improvement to better represent the described object. In particular, if a certain feature is missing, or a feature has been drawn in the incorrect location, suggest to fix the feature. Provide only one very short sentence."
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "max_tokens": 300
    }
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    response_json = response.json()
    content = response_json['choices'][0]['message']['content']
    tokens_used = response_json['usage']['total_tokens']
    return content, tokens_used

def main():
    # OpenAI API Key
    api_key = API_KEY

    # CLIP Model Properties:
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32") 

    # Conversation history
    conversation_history = []

    # Delete existing files in the folders
    delete_files_in_folder("./svg")
    delete_files_in_folder("./png")

    # Obtain user input and number of iterations
    user_input = get_user_input()
    iterations = int(get_number_of_iterations())
    print("\n")
    clip_input = ["graphic of " + user_input, "not a graphic of " + user_input]

    # Initial feedback
    feedback = "Nothing"

    # Iteration count
    first_iteration = True

    # Reinforcement learning
    for i in range(iterations):
        print(f"========Iteration {i} has started========")

        # PNG and SVG file paths
        svg_rl_folder = f"./svg/vector{i}.svg"
        png_rl_folder = f"./png/raster{i}.png"

        # Generate the SVG content
        svg_content, tokens_one = generate_svg_code(user_input, first_iteration, conversation_history, feedback, api_key)
        # Extract svg code from GPT output
        svg_content = extract_svg_code(svg_content)
        with open(svg_rl_folder, 'w') as file:
            file.write(svg_content)

        # Convert SVG to PNG
        convert_svg_to_png(svg_rl_folder, png_rl_folder)
        # Encode the PNG to base64
        base64_image = encode_image(png_rl_folder)
        # Get the feedback
        feedback, tokens_two = get_image_feedback(base64_image, user_input, api_key)

        # CLIP Model
        clip_image = Image.open(png_rl_folder)
        inputs = processor(text=clip_input, images=clip_image, return_tensors="pt", padding=True)
        outputs = model(**inputs)
        # Raw Similarity Score
        logits_per_image = outputs.logits_per_image 
        # Probability
        probability_tensor = logits_per_image.softmax(dim=1) 
        probability_value = probability_tensor[0][0].item()

        first_iteration = False
        print("Feedback: " + feedback)
        print("Tokens used: " + str(tokens_one + tokens_two))
        print("CLIP Probability: " + str(probability_value))
        print("\n")
        

if __name__ == "__main__":
    main()
